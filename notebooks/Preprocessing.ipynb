{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyOymuSj7PLwYGX7gRivst6B"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing in NLP"
   ],
   "metadata": {
    "id": "_XxTOWUlGmT0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What is it?\n"
   ],
   "metadata": {
    "id": "tC4k5e_XGzYz"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing in NLP refers to the series of steps taken to clean, normalize, and prepare raw text data before it is fed into a machine learning or deep learning model.\n",
    "\n",
    "Proper preprocessing is crucial for improving the performance of NLP models by ensuring the text data is in a suitable format and reducing noise.\n",
    "\n",
    "Key Preprocessing Steps\n",
    "\n",
    "\t1. Tokenization Splitting text into individual words, phrases, or tokens.\n",
    "\t2. Lowercasing\n",
    "\t3. Removing Punctuation\n",
    "\t4. Removing Stop Words\n",
    "\t5. Stemming Reducing words to their root form by removing suffixes.Example: “running” -> “run”\n",
    "\t6. Lemmatization Reducing words to their base or dictionary form, considering the context. Example: “better” -> “good”\n",
    "\t7. Handling Special Characters\n",
    "\t8. Removing or replacing special characters and digits. Example: “Price is $100” -> “Price is”\n",
    "\t9. Text Normalization, Standardizing text by correcting spelling mistakes, expanding contractions, and normalizing numbers. Example: “can’t” -> “cannot”, “2day” → “today”"
   ],
   "metadata": {
    "id": "y63i6rfJHC52"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "gTn41hepGuE0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## What for?"
   ],
   "metadata": {
    "id": "Jngpu_PmG3Mt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uses of Preprocessing\n",
    "\n",
    "1. Improving Model Accuracy: Reduces noise and irrelevant information, leading to more accurate and reliable models.\n",
    "2. Reducing Vocabulary Size: removing stop words, punctuation, and special characters, the vocabulary size is reduced, which simplifies the model and speeds up training."
   ],
   "metadata": {
    "id": "1w0opbT3HS6h"
   }
  },
  {
   "cell_type": "code",
   "source": "!pip install nltk",
   "metadata": {
    "id": "-4RIWFqtG52a",
    "ExecuteTime": {
     "end_time": "2024-07-09T10:12:17.126290Z",
     "start_time": "2024-07-09T10:12:12.686362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Collecting click (from nltk)\r\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\r\n",
      "Requirement already satisfied: joblib in /Users/aymanelsayeed/PycharmProjects/nlplecture/venv/lib/python3.12/site-packages (from nltk) (1.4.2)\r\n",
      "Collecting regex>=2021.8.3 (from nltk)\r\n",
      "  Downloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.9/40.9 kB\u001B[0m \u001B[31m419.0 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting tqdm (from nltk)\r\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m1.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.5/1.5 MB\u001B[0m \u001B[31m4.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading regex-2024.5.15-cp312-cp312-macosx_11_0_arm64.whl (278 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m278.5/278.5 kB\u001B[0m \u001B[31m6.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m97.9/97.9 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m3.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: tqdm, regex, click, nltk\r\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2024.5.15 tqdm-4.66.4\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.1.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example"
   ],
   "metadata": {
    "id": "imkdKR9cHiYt"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Example Workflow\n",
    "\n",
    "Consider the sentence: “Natural Language Processing (NLP) is fascinating!”\n",
    "\n",
    "1. Tokenization: “Natural Language Processing (NLP) is fascinating!” -->  [“Natural”, “Language”, “Processing”, “(NLP)”, “is”, “fascinating”, “!”]\n",
    "2. Lowercasing: [“Natural”, “Language”, “Processing”, “(NLP)”, “is”, “fascinating”, “!”] --> [“natural”, “language”, “processing”, “(nlp)”, “is”, “fascinating”, “!”]\n",
    "3. Removing Punctuation: [“natural”, “language”, “processing”, “(nlp)”, “is”, “fascinating”, “!”] --> [“natural”, “language”, “processing”, “nlp”, “is”, “fascinating”]\n",
    "4. Removing Stop Words: [“natural”, “language”, “processing”, “nlp”, “is”, “fascinating”] --> [“natural”, “language”, “processing”, “nlp”, “fascinating”]\n",
    "5. Lemmatization: [“natural”, “language”, “processing”, “nlp”, “fascinating”] --> [“natural”, “language”, “process”, “nlp”, “fascinate”]\n",
    "\n",
    "Preprocessing prepares this sentence for vectorization and subsequent machine learning tasks, ensuring the text is clean, uniform, and ready for analysis."
   ],
   "metadata": {
    "id": "aDgWBRZ5HkGV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to do it?"
   ],
   "metadata": {
    "id": "KJ6WjSc6G6V7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Packages\n",
    "\n",
    "* NLTK\n",
    "* Spacy\n",
    "* TextBlob\n",
    "* Gensim\n",
    "* Scikit-learn\n",
    "* Pandas\n",
    "* Numpy\n",
    "* String"
   ],
   "metadata": {
    "id": "k0QsX9fRKrDT"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ],
   "metadata": {
    "id": "gfX6GnC_KuwN",
    "ExecuteTime": {
     "end_time": "2024-07-17T10:00:34.388852Z",
     "start_time": "2024-07-17T10:00:33.527579Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aymanelsayeed/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": "### Examples\n",
   "metadata": {
    "id": "thjtP54CKwek"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Remove stop words"
  },
  {
   "cell_type": "code",
   "source": "text1 = \"Ethics are built right into the ideals and objectives of the United Nations \"",
   "metadata": {
    "id": "1I81XRrBKyHC",
    "ExecuteTime": {
     "end_time": "2024-07-09T10:14:41.310403Z",
     "start_time": "2024-07-09T10:14:41.308315Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "' '.join([word for word in text1.split() if word.lower() not in stopwords.words('english')])",
   "metadata": {
    "id": "v1ALkKkOG80T",
    "ExecuteTime": {
     "end_time": "2024-07-09T10:15:56.125589Z",
     "start_time": "2024-07-09T10:15:56.121258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethics built right ideals objectives United Nations'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Remove Punctuation"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:00:26.735485Z",
     "start_time": "2024-07-17T10:00:26.733375Z"
    }
   },
   "cell_type": "code",
   "source": "text2 = \"Hello! How are you doing today?\"",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T10:00:36.641536Z",
     "start_time": "2024-07-17T10:00:36.635720Z"
    }
   },
   "cell_type": "code",
   "source": "text2.translate(str.maketrans('', '', string.punctuation))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello How are you doing today'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Stemming"
  },
  {
   "cell_type": "code",
   "source": [
    "input1 = \"List listed lists listing listings\"\n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ],
   "metadata": {
    "id": "Z5zwVhP1II0s",
    "ExecuteTime": {
     "end_time": "2024-07-09T10:21:34.245447Z",
     "start_time": "2024-07-09T10:21:34.242969Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'lists', 'listing', 'listings']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "porter = nltk.PorterStemmer()",
   "metadata": {
    "id": "pM5tiJSiII9_",
    "ExecuteTime": {
     "end_time": "2024-07-09T10:21:52.985165Z",
     "start_time": "2024-07-09T10:21:52.983365Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T10:22:02.802092Z",
     "start_time": "2024-07-09T10:22:02.799516Z"
    }
   },
   "cell_type": "code",
   "source": "[porter.stem(word) for word in words1]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Lemmatization"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T10:22:51.239733Z",
     "start_time": "2024-07-09T10:22:51.237860Z"
    }
   },
   "cell_type": "code",
   "source": "WNlemma = nltk.WordNetLemmatizer()",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T10:22:52.083510Z",
     "start_time": "2024-07-09T10:22:51.606784Z"
    }
   },
   "cell_type": "code",
   "source": "[WNlemma.lemmatize(t) for t in words1]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'list', 'listing', 'listing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Practise"
   ],
   "metadata": {
    "id": "jic_NEDxIJQO"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 1\n",
    "\n",
    "* Read the file `twitter.csv`\n",
    "* Remove all the stop words from the text. save the output in a new column `text_without_stopwords`\n",
    "\n",
    "Write function to remove stopwords from the text"
   ],
   "metadata": {
    "id": "e48k1ynvIQQa"
   }
  },
  {
   "cell_type": "code",
   "source": "# Write answer here\n",
   "metadata": {
    "id": "IcGKfrBZIYDT",
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:31.560Z",
     "start_time": "2024-07-09T13:27:31.548775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   rating       date         variation  \\\n",
       "0       5  31-Jul-18  Charcoal Fabric    \n",
       "1       5  31-Jul-18  Charcoal Fabric    \n",
       "2       4  31-Jul-18    Walnut Finish    \n",
       "3       5  31-Jul-18  Charcoal Fabric    \n",
       "4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:35.761636Z",
     "start_time": "2024-07-09T13:27:32.351320Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 2\n",
    "\n",
    "Remove all the Punctuation from the `text_without_stopwords` column. Save the output in a new column `text_without_sp`\n",
    "\n",
    "Write function to remove punctuation from the text"
   ],
   "metadata": {
    "id": "Kir3QVXVJM0O"
   }
  },
  {
   "cell_type": "code",
   "source": "# Write answer here\n",
   "metadata": {
    "id": "rei6FlitJQSE",
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:37.770723Z",
     "start_time": "2024-07-09T13:27:37.756230Z"
    }
   },
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:38.512851Z",
     "start_time": "2024-07-09T13:27:38.510139Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love Echo'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:43.975237Z",
     "start_time": "2024-07-09T13:27:43.972812Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Love my Echo!'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 3\n",
    "\n",
    "Apply stemming on the `text_without_sp` column. Save the output in a new column `stemmed_text`\n",
    "\n",
    "write function to apply stemming on the text"
   ],
   "metadata": {
    "id": "zzaBOITJJew2"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "q6rbX7ueJijt",
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:47.461701Z",
     "start_time": "2024-07-09T13:27:47.128531Z"
    }
   },
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 4\n",
    "\n",
    "Apply Lemmatization on the `text_without_sp` column. Save the output in a new column `lemmatized_text`\n",
    "\n",
    "write function to apply lemmatization on the text"
   ],
   "metadata": {
    "id": "gsrTmSHSJlCK"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "Gn-TeJl9Jnbh",
    "ExecuteTime": {
     "end_time": "2024-07-09T13:27:49.283960Z",
     "start_time": "2024-07-09T13:27:49.187512Z"
    }
   },
   "outputs": [],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 5\n",
    "\n",
    "Write a function that takes a string as input and returns a clean text after:\n",
    "\n",
    "* Removing stopwords,\n",
    "* Removing Punctuation\n",
    "* Applying stemming / lemmatizing."
   ],
   "metadata": {
    "id": "CioCnpCiJovH"
   }
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "id": "8b_9k23RJrQN",
    "ExecuteTime": {
     "end_time": "2024-07-09T20:29:40.887174Z",
     "start_time": "2024-07-09T20:29:40.882747Z"
    }
   },
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quiz 6\n",
    "\n",
    "Save the final dataframe in a new csv file."
   ],
   "metadata": {
    "id": "h2GkPrjeJss_"
   }
  },
  {
   "cell_type": "code",
   "source": "# write answer here\n",
   "metadata": {
    "id": "4yaaGeDlJuEx",
    "ExecuteTime": {
     "end_time": "2024-07-09T13:28:12.862009Z",
     "start_time": "2024-07-09T13:28:12.834676Z"
    }
   },
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Quiz 7\n",
    "\n",
    "Do the same preprocessing on the `tweet.csv`  file."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
