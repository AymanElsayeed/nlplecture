{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-14T15:32:42.488205Z",
     "start_time": "2024-07-14T15:32:42.485757Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Load the data\n",
    "\n",
    "0: 20 newsgroups dataset\n",
    "\n",
    "1: spam dataset\n",
    "\n",
    "2: twitter dataset\n",
    "\n",
    "3: amazon reviews dataset"
   ],
   "id": "427135ed5dadf7f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.866121Z",
     "start_time": "2024-07-14T15:29:52.864323Z"
    }
   },
   "cell_type": "code",
   "source": "data_set  = 3",
   "id": "940b71f851c43e4d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load the 20 newsgroups dataset\n",
    "\n",
    "Split the data into train and test\n"
   ],
   "id": "2e1f32888a9b0cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.868532Z",
     "start_time": "2024-07-14T15:29:52.866686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "\n",
    "if data_set ==0:\n",
    "    \n",
    "    categories = ['rec.autos', 'sci.med', 'comp.graphics']\n",
    "    \n",
    "    data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'), categories=categories)\n",
    "    \n",
    "    # split the data into train and test\n",
    "\n"
   ],
   "id": "1ddca89bf105f7f2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the spam dataset",
   "id": "f697836c6a904b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:47:15.774143Z",
     "start_time": "2024-07-14T15:47:15.771720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if data_set == 1:\n",
    "    spam = pd.read_csv('../../assets/spam.csv')\n",
    "    # do one hot encoding for the target variable\n",
    "    spam['target'] = pd.get_dummies(spam['target'], drop_first=True, dtype=int)\n",
    "\n",
    "    # split the data into train and test\n",
    "    train_set, test_set = 0,0\n",
    "    \n",
    "    x_train = train_set['text']\n",
    "    y_train = train_set['target'].to_numpy()\n",
    "    \n",
    "    x_test = test_set['text']\n",
    "    y_test = test_set['target'].to_numpy()"
   ],
   "id": "f1a620578fbf625a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.872900Z",
     "start_time": "2024-07-14T15:29:52.871542Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5b6a86101912f94",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.874825Z",
     "start_time": "2024-07-14T15:29:52.873640Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b07aeafd6121e7fb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the twitter dataset",
   "id": "d0993104226b1602"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.877971Z",
     "start_time": "2024-07-14T15:29:52.875408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if data_set == 2:\n",
    "    twitter = pd.read_csv('../../assets/twitter.csv')\n",
    "    # drop id column\n",
    "    twitter = twitter.drop('id', axis=1)\n",
    "\n",
    "    # split the data into train and test\n",
    "    \n",
    "    x_train = train_set['tweet']\n",
    "    y_train = train_set['label'].to_numpy()\n",
    "    \n",
    "    x_test = test_set['tweet']\n",
    "    y_test = test_set['label'].to_numpy()"
   ],
   "id": "7c0d891d3f27c4cd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load amazon reviews dataset",
   "id": "3f12150262be6b29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.890779Z",
     "start_time": "2024-07-14T15:29:52.879907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if data_set == 3:\n",
    "    amazon = pd.read_csv('../../assets/amazon_reviews.csv')\n",
    "    # drop na rows\n",
    "    amazon = amazon.dropna()\n",
    "    \n",
    "    # split the data into train and test\n",
    "\n",
    "    x_train = train_set['verified_reviews']\n",
    "    y_train = train_set['feedback'].to_numpy()\n",
    "    \n",
    "    x_test = test_set['verified_reviews']\n",
    "    y_test = test_set['feedback'].to_numpy()"
   ],
   "id": "544583b2dc95f443",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.892753Z",
     "start_time": "2024-07-14T15:29:52.891416Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ad2bff2dbb2b3321",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:52.894394Z",
     "start_time": "2024-07-14T15:29:52.893324Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "79bfb51cec94802b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vectorize the text data",
   "id": "b20df38fc27dbe9b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "\n",
    "Write a function to tokenize the text data\n",
    "\n",
    "* Remove the punctuation\n",
    "* Remove stopwords\n",
    "* Remove non-alphabetic characters\n",
    "* Convert to lowercase\n",
    "* Stemming or lemmatization\n",
    "* Return the tokenized text"
   ],
   "id": "9dd79cbeff73267"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:41:54.492278Z",
     "start_time": "2024-07-14T15:41:54.490460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_1(text):\n",
    "    # remove the punctuation\n",
    "    \n",
    "    # remove stopwords\n",
    "    \n",
    "    # remove non-alphabetic characters\n",
    "    \n",
    "    # convert to lowercase\n",
    "    \n",
    "    # stemming\n",
    "    \n",
    "    # lemmatization\n",
    "    \n",
    "    return text"
   ],
   "id": "471e787ae36f37ce",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Vectorize the text data\n",
    "\n",
    "*  max_features = 100\n",
    "* use CountVectorizer / TfidfVectorizer / ngram_range\n",
    "    * with the tokenizer function\n",
    "    * without the tokenizer function\n",
    "    * with ngam_range\n",
    "    * with stop_words\n",
    "    * without stop_words"
   ],
   "id": "9414917ddf62a4df"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:37:22.916223Z",
     "start_time": "2024-07-14T15:37:22.914382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Vectorize the text data\n",
    "max_features = 100\n"
   ],
   "id": "94898af8a4f03e4",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = vectorizer.fit_transform(x_train)\n",
    "\n",
    "X_test = vectorizer.transform(x_test)"
   ],
   "id": "ff15eb395c8aaa27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:56.572529Z",
     "start_time": "2024-07-14T15:29:56.569698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert feature matrices to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.toarray()).float()\n",
    "X_test_tensor = torch.tensor(X_test.toarray()).float()\n",
    "\n",
    "# Convert target vectors to PyTorch tensors\n",
    "y_train_tensor = torch.tensor(y_train)\n",
    "y_test_tensor = torch.tensor(y_test)"
   ],
   "id": "10336a0bb3de7295",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:32:03.983927Z",
     "start_time": "2024-07-14T15:32:03.981975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1d190d014a00e7b6",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:56.578724Z",
     "start_time": "2024-07-14T15:29:56.576973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape the feature matrices\n",
    "X_train_seq = X_train_tensor.view(X_train_tensor.shape[0], -1, X_train_tensor.shape[1])"
   ],
   "id": "5443dcbfffdb7dab",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:56.587453Z",
     "start_time": "2024-07-14T15:29:56.585411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape the feature matrices\n",
    "X_test_seq = X_test_tensor.view(X_test_tensor.shape[0],-1,X_test_tensor.shape[1])"
   ],
   "id": "af4b7ab2a7c4a420",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:29:56.605626Z",
     "start_time": "2024-07-14T15:29:56.603387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Complete the RNN class\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "id": "ab8fe9b7eec90774",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_size = 33 # this should be equal to the number of features in X_train_tensor\n",
    "hidden_size = 32\n",
    "num_layers = 2\n",
    "num_classes = 2"
   ],
   "id": "9ef1c98faad0d7fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:39:07.740238Z",
     "start_time": "2024-07-14T15:39:07.737262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the model\n",
    "rnn_model = RNNModel(input_size, hidden_size, num_layers, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(rnn_model.parameters(), lr=0.01) "
   ],
   "id": "e003cdf42dbdce1a",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question\n",
    "\n",
    "Change the optimizer to SGD and ASGD and compare the results"
   ],
   "id": "a896299d167235df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5c7ba686d257e4c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:30:21.249035Z",
     "start_time": "2024-07-14T15:30:21.195385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Train the model for ten epochs and zero the gradients\n",
    "for epoch in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    # outputs = rnn_model(X_train_seq)\n",
    "    outputs = rnn_model(X_train_seq)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch: {epoch+1}, Loss: {loss.item()}')"
   ],
   "id": "ef77473e557497e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.5903684496879578\n",
      "Epoch: 2, Loss: 0.3559195399284363\n",
      "Epoch: 3, Loss: 0.3066563606262207\n",
      "Epoch: 4, Loss: 0.29748037457466125\n",
      "Epoch: 5, Loss: 0.29428449273109436\n",
      "Epoch: 6, Loss: 0.2895662784576416\n",
      "Epoch: 7, Loss: 0.2821877896785736\n",
      "Epoch: 8, Loss: 0.27335816621780396\n",
      "Epoch: 9, Loss: 0.26611509919166565\n",
      "Epoch: 10, Loss: 0.26439353823661804\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Calculate the \n",
    "* accuracy\n",
    "* precision\n",
    "* recall\n",
    "* F1 score"
   ],
   "id": "bfe4b2747b32246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:30:24.871354Z",
     "start_time": "2024-07-14T15:30:24.867936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create an instance of the metrics\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "# create an instance of  precision, recall, and F1 score\n"
   ],
   "id": "d10c823887b85ae8",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Question\n",
    "\n",
    "Run the model on the test data"
   ],
   "id": "4e387d44f9740081"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "37487c4c36b0648"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:56:16.446133Z",
     "start_time": "2024-07-14T15:56:16.442630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate the predictions\n",
    "_, predicted = torch.max(outputs, 1)"
   ],
   "id": "5859a104ccf0b455",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "3bda4ad57e58f23a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:30:26.781336Z",
     "start_time": "2024-07-14T15:30:26.773887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate the metrics\n",
    "accuracy_score = accuracy(predicted, y_test_tensor)\n",
    "\n",
    "# Calculate the precision, recall, and F1 score\n"
   ],
   "id": "6e926a8e2d882d2",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:30:27.558927Z",
     "start_time": "2024-07-14T15:30:27.556600Z"
    }
   },
   "cell_type": "code",
   "source": "print(\"RNN Model - Accuracy: {}, Precision: {}, Recall: {}, F1 Score: {}\".format(accuracy_score, precision_score, recall_score, f1_score))",
   "id": "4cdc6879b9430a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Model - Accuracy: 0.8999999761581421, Precision: 0.8999999761581421, Recall: 0.8999999761581421, F1 Score: 0.8999999761581421\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-14T15:30:34.084477Z",
     "start_time": "2024-07-14T15:30:34.082855Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "87efe676bfc46229",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e3ab5707988cf7f9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
